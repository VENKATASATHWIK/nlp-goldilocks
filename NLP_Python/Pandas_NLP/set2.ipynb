{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae9fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "\n",
    "# Mock dataset with different text patterns\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 4, 5],\n",
    "    \"text\": [\n",
    "        \"Natural Language Processing is FUN!\",\n",
    "        \"I LOVE AI and NLP.\",\n",
    "        \"Visit https://example.com for FREE info.\",\n",
    "        \"Numbers 123 are here.\",\n",
    "        \"Spam!!! spam spam...\"\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4683dff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0,text length is 35\n",
      "index 1,text length is 18\n",
      "index 2,text length is 40\n",
      "index 3,text length is 21\n",
      "index 4,text length is 20\n"
     ]
    }
   ],
   "source": [
    "# Example 21: Loop through each row and print text length\n",
    "df  = pd.DataFrame(data)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    text_len = len(row[\"text\"])\n",
    "    print(f\"index {index},text length is {text_len}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d518cf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         natural language processing is fun!\n",
       "1                          i love ai and nlp.\n",
       "2    visit https://example.com for free info.\n",
       "3                       numbers 123 are here.\n",
       "4                        spam!!! spam spam...\n",
       "Name: text_lower, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 22: List comprehension to lowercase all texts\n",
    "\n",
    "df[\"text_lower\"] = [text.lower() for text in df[\"text\"]]\n",
    "df[\"text_lower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa32329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Natural Language Processing is FUN\n",
      "1                      I LOVE AI and NLP\n",
      "2    Visit httpsexamplecom for FREE info\n",
      "3                   Numbers 123 are here\n",
      "4                         Spam spam spam\n",
      "Name: text_no_punc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example 23: List comprehension to remove punctuation\n",
    "\n",
    "df[\"text_no_punc\"] = [re.sub(r'[^\\w\\s]',\"\",text) for text in df[\"text\"]]\n",
    "print(df[\"text_no_punc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d87bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [Natural, Language, Processing, is, FUN]\n",
      "1                      [I, LOVE, AI, and, NLP]\n",
      "2    [Visit, httpsexamplecom, for, FREE, info]\n",
      "3                    [Numbers, 123, are, here]\n",
      "4                           [Spam, spam, spam]\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example 24: List comprehension to tokenize text\n",
    "df[\"tokens\"] = [text.split() for text in df[\"text_no_punc\"]]\n",
    "print(df[\"tokens\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013163b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['Natural', 'Language', 'Processing', 'is', 'FUN'], 2: ['I', 'LOVE', 'AI', 'and', 'NLP'], 3: ['Visit', 'httpsexamplecom', 'for', 'FREE', 'info'], 4: ['Numbers', '123', 'are', 'here'], 5: ['Spam', 'spam', 'spam']}\n"
     ]
    }
   ],
   "source": [
    "# Example 25: Loop to create dictionary mapping id → tokens\n",
    "id_token_dict = {}\n",
    "for i, row in df.iterrows():\n",
    "    id_token_dict[row[\"id\"]] = row[\"tokens\"]\n",
    "print(id_token_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3df2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                             text_stripped\n",
      "0   1       Natural Language Processing is FUN!\n",
      "1   2                        I LOVE AI and NLP.\n",
      "2   3  Visit https://example.com for FREE info.\n",
      "3   4                     Numbers 123 are here.\n",
      "4   5                      Spam!!! spam spam...\n"
     ]
    }
   ],
   "source": [
    "# Example 26: Lambda to strip whitespace\n",
    "df[\"text_stripped\"]  =df[\"text\"].apply(lambda x:x.strip())\n",
    "print(df[['id', 'text_stripped']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "662d577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                          text_no_url\n",
      "0   1  Natural Language Processing is FUN!\n",
      "1   2                   I LOVE AI and NLP.\n",
      "2   3           Visit <URL> for FREE info.\n",
      "3   4                Numbers 123 are here.\n",
      "4   5                 Spam!!! spam spam...\n"
     ]
    }
   ],
   "source": [
    "# Example 27: Lambda to replace URLs with <URL> placeholder\n",
    "\n",
    "df[\"text_no_url\"] = df[\"text\"].apply(lambda x: re.sub(r'http\\S+',\"<URL>\",x))\n",
    "print(df[[\"id\",\"text_no_url\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7573b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  token_count\n",
      "0   1            5\n",
      "1   2            5\n",
      "2   3            5\n",
      "3   4            4\n",
      "4   5            3\n"
     ]
    }
   ],
   "source": [
    "# Example 28: map() to count tokens in each text\n",
    "df[\"token_count\"] = df[\"token\"].map(len)\n",
    "print(df[[\"id\",\"token_count\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cbacb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: contain_nlp, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Example 29: map() to check if text contains keyword 'nlp'\n",
    "df[\"contain_nlp\"] = df[\"text_lower\"].map(lambda x: \"nlp\" in x)\n",
    "print(df[\"contain_nlp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586776ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                  text_num_normalized\n",
      "0   1   Natural Language Processing is FUN\n",
      "1   2                    I LOVE AI and NLP\n",
      "2   3  Visit httpsexamplecom for FREE info\n",
      "3   4                 Numbers 000 are here\n",
      "4   5                       Spam spam spam\n"
     ]
    }
   ],
   "source": [
    "# Example 30: Nested lambda to clean numbers (replace digits with '0')\n",
    "\n",
    "df[\"text_num_normalized\"] = df[\"text_no_punc\"].map(lambda x:re.sub(r'\\d',\"0\",x))\n",
    "print(df[[\"id\",\"text_num_normalized\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e6add",
   "metadata": {},
   "source": [
    " tokenization + aggregation + advanced regex — this is where text becomes features for models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c370e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
