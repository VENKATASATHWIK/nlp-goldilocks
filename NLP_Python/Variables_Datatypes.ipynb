{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed3632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "x =10\n",
    "y = 3.5 \n",
    "print(type(x),type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7475d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, sathvik\n"
     ]
    }
   ],
   "source": [
    "#2 \n",
    "name = \"sathvik\"\n",
    "greeting  = \"hello, \"+ name \n",
    "print(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b35fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6\n"
     ]
    }
   ],
   "source": [
    "#3 \n",
    "my_list  = [1,2,3]\n",
    "my_tuple = (4,5,6)\n",
    "print(my_list[1],my_tuple[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518dbe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = \"5\"\n",
    "b = 3\n",
    "result = int(a) + b\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "183bba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# 2 Make a set from a list and remove duplicates\n",
    "\n",
    "nums = [1,2,2,3,3,3]\n",
    "unique = set(nums)\n",
    "print(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f49c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sathvik\n",
      "{'name': 'sathvik', 'age': 25}\n"
     ]
    }
   ],
   "source": [
    "data = {\"name\":\"sathvik\",\"age\":24}\n",
    "print(data[\"name\"])\n",
    "data[\"age\"]+=1\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d7680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#task 4\n",
    "x = True\n",
    "y = False \n",
    "print(x+y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c1d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "sentence  = \"Python is powerful, flexible, and fun!\"\n",
    "\n",
    "count = 0\n",
    "lst = sentence.split()\n",
    "count = len(lst)\n",
    "dictionary = {\"word_count\":count}\n",
    "print(type(dictionary))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759652f",
   "metadata": {},
   "source": [
    "#### String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "#concatination\n",
    "first = \"hello\"\n",
    "second = \"world\"\n",
    "print(first+\" \"+second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d4ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sathvik nlp SATHVIK NLP\n"
     ]
    }
   ],
   "source": [
    "#upper and lower \n",
    "text = \"sathvik NLP\"\n",
    "print(text.lower(),text.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a07672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded text\n"
     ]
    }
   ],
   "source": [
    "# strip ---- remove spaces \n",
    "text = \"    padded text     \"\n",
    "print(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0b5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is intresting and I am passionate to learn\n"
     ]
    }
   ],
   "source": [
    "#replace()\n",
    "sentence  =\"NLP is hard and I am passionate to learn\"\n",
    "print(sentence.replace(\"hard\",\"intresting\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818e0a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "# startswith() and .endswith()\n",
    "\n",
    "url = \"https://chat.openai.com\"\n",
    "print(url.startswith(\"https\"), url.endswith(\".com\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bce925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'is', 'magical']\n"
     ]
    }
   ],
   "source": [
    "# split()\n",
    "sentence = \"Deep learning is magical\"\n",
    "print(sentence.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'grape']\n"
     ]
    }
   ],
   "source": [
    "#split() with delimiter\n",
    "csv = \"apple,banana,grape\"\n",
    "print(csv.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15889bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love python\n"
     ]
    }
   ],
   "source": [
    "#join()\n",
    "words = [\"I\",\"love\",\"python\"]\n",
    "print(\" \".join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb5fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat\n"
     ]
    }
   ],
   "source": [
    "name = \"sathvik\"\n",
    "print(name[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9a74cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsformer\n"
     ]
    }
   ],
   "source": [
    "word = \"Transformer\"\n",
    "print(word[-8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "188cf30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#in\n",
    "text = \"This is NLP\"\n",
    "print(\"NLP\" in text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0cb0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# find() and index()\n",
    "text  =\"machine learning\"\n",
    "print(text.find(\"learn\"))\n",
    "print(text.index(\"learn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5d39173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "text = \"Spam spam spam ham\"\n",
    "print(text.lower().count(\"spam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0f4fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(\"Natural language processing\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e1ea063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "text  =\"  Hello World!!!  \"\n",
    "clean = text.strip().lower().replace(\"!\",\"\")\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40531b53",
   "metadata": {},
   "source": [
    "#### Mini challenges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep : 4\n",
      "learning : 8\n",
      "models : 6\n",
      "are : 3\n",
      "data : 4\n",
      "hungry : 6\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "sentence  = \"deep learning models are data hungry\"\n",
    "lst  = sentence.split()\n",
    "for char in lst:\n",
    "    print(char,\":\",len(char) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "text = \"AI: The revolution is real!\"\n",
    "print(text.startswith(\"AI:\"),text.endswith(\"!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53158553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre trained language models\n"
     ]
    }
   ],
   "source": [
    "#3 Replace all - with spaces and convert text to lowercase.\n",
    "text = \"Pre-Trained-Language-Models\"\n",
    "print(text.replace(\"-\",\" \").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3457d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-transformers-rocks\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "words = [\"huggingface\", \"transformers\", \"rocks\"]\n",
    "\n",
    "output = \"-\".join(words)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "661723a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "text = \"Natural Language Processing\"\n",
    "text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fb3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is nlp it's fun\n",
      "\n",
      "the word count is :  5\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "text = \"  What is NLP? It's fun!!!  \"\n",
    "# Goal: Clean it fully, then count words\n",
    "\n",
    "clean = text.strip().lower().replace(\"?\",\"\").replace(\"!\",\"\")\n",
    "word_count = len(clean.split())\n",
    "print(clean)\n",
    "print(\"\")\n",
    "print(\"the word count is : \",word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "tweet = \"#AI is the future. #ML and #DL are part of it. #AI\"\n",
    "# Output: Count of hashtags\n",
    "print(\"#\" in tweet)\n",
    "print(tweet.count(\"#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52d956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Language', 'Understanding']\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "sentence = \"Foundation: Language-Understanding-and-Reasoning\"\n",
    "# Output: ['Language', 'Understanding']\n",
    "# Hint: Use split + slicing logic\n",
    "\n",
    "new = sentence.replace(\"-\",\" \").replace(\":\",\"\")\n",
    "lst = new.split()\n",
    "lst_2  =[]\n",
    "\n",
    "for char in lst:\n",
    "    if char==\"Language\":\n",
    "        lst_2.append(char)\n",
    "    if char==\"Understanding\":\n",
    "        lst_2.append(char)\n",
    "        \n",
    "print(lst_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa524f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Language', 'Understanding']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Foundation: Language-Understanding-and-Reasoning\"\n",
    "words = sentence.replace(\":\",\"\").replace(\"-\",\" \").split()\n",
    "result = [word for word in words if word in [\"Language\",\"Understanding\"]]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6307c6c",
   "metadata": {},
   "source": [
    "### Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b311087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'embedding', 'transformers']\n"
     ]
    }
   ],
   "source": [
    "words = [\"token\",\"embedding\",\"transformers\"]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15f1d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token transformers\n"
     ]
    }
   ],
   "source": [
    "# by index \n",
    "print(words[0],words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0efceaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'embedding']\n"
     ]
    }
   ],
   "source": [
    "print(words[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d9d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'embedding', 'transformers', 'attention']\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "words.append(\"attention\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "382da0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'sequence', 'embedding', 'transformers', 'attention']\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "words.insert(1,\"sequence\")\n",
    "print(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a01d979f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "words.remove(\"embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42e23272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'sequence', 'transformers', 'attention']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2042b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequence', 'transformers', 'attention']\n"
     ]
    }
   ],
   "source": [
    "del words[0]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENCE\n",
      "TRANSFORMERS\n",
      "ATTENTION\n"
     ]
    }
   ],
   "source": [
    "#8 loops\n",
    "for word in words:\n",
    "    print(word.upper())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6443712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#9 check membership\n",
    "print(\"attention\" in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "381aaba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 30 10\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "nums = [10,20,30]\n",
    "print(sum(nums),max(nums),min(nums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30a129e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "#sort list \n",
    "nums.sort()\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cebd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list comprehension\n",
    "squares = [x*x for x in range(5)]\n",
    "squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19add26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "# 13 list comprehension with condition\n",
    "even = [x for x in range(10) if x%2==0]\n",
    "print(even )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e585eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 6, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "#14 list comp with split()\n",
    "text = \"NLP with Python is powerful\"\n",
    "words = text.split()\n",
    "lengths = [len(w) for w in words]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15 nested list comprehensions , flattening \n",
    "matrix = [[1,2],[3,4]]\n",
    "flattened = [num for row in matrix for num in row ]\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "911a381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "#16 \n",
    "tokens = [\"hello\",\"WORLD\",\"NLP\"]\n",
    "cleaned = [word.lower() for word in tokens]\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb38cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'nlp']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#17 remove punctuations\n",
    "tokens = [\"hello\",\"!\",\"world\",\".\",\"nlp\"]\n",
    "cleaned = [word for word in tokens if word.isalpha()]\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9c02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome', 'tutorial']\n"
     ]
    }
   ],
   "source": [
    "#18 remove stopwords \n",
    "\n",
    "tokens = tokens = [\"this\", \"is\", \"an\", \"awesome\", \"tutorial\"]\n",
    "stopwords= [\"is\",\"an\",\"this\"]\n",
    "filtered = [word for word in tokens if word not in stopwords]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe0af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 5]\n"
     ]
    }
   ],
   "source": [
    "#19 Length of each token\n",
    "tokens = [\"deep\", \"learning\", \"rocks\"]\n",
    "lengths = [len(word) for word in tokens]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611e1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bert', 'Gpt', 'Roberta']\n"
     ]
    }
   ],
   "source": [
    "#20 capitalize the first letter \n",
    "tokens =  [\"bert\", \"gpt\", \"roberta\"]\n",
    "capitalized = [w.capitalize() for w in tokens]\n",
    "print(capitalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89400b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'is', 'fun']\n"
     ]
    }
   ],
   "source": [
    "#21 Replace word if condition met\n",
    "words =  [\"ai\", \"is\", \"boring\"]\n",
    "fixed = [\"fun\" if w==\"boring\" else w for w in words]\n",
    "print(fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959a73e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25', '90', '1']\n"
     ]
    }
   ],
   "source": [
    "#22 extract digits from strings \n",
    "texts  = [\"age25\",\"score-90\",\"rank:1\"]\n",
    "digits = [\"\".join([ch for ch in t if ch.isdigit()]) for t in texts]\n",
    "print(digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f558ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'orange']\n"
     ]
    }
   ],
   "source": [
    "#23 Filter only words starting with vowel\n",
    "words = [\"apple\", \"banana\", \"orange\", \"grape\"]\n",
    "vowels = [w for w  in words if w[0].lower() in \"aeiou\"]\n",
    "print(vowels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "#24 Remove short tokens (length < 3)\n",
    "tokens = [\"a\", \"on\", \"is\", \"data\", \"AI\"]\n",
    "words = [w for w in tokens if len(w)>3]\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1081ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False]\n"
     ]
    }
   ],
   "source": [
    "#25 Boolean flag for each word if it has 'a'\n",
    "tokens  = [\"data\",\"code\",\"python\"]\n",
    "flags = [\"a\" in word for word in tokens]\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce194fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', '456']\n"
     ]
    }
   ],
   "source": [
    "# 26 Remove numbers from a list of mixed tokens\n",
    "tokens = [\"123\", \"hello\", \"456\", \"nlp\"]\n",
    "words_only = [w for w in tokens if w.isdigit()]\n",
    "print(words_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628be739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'hi'), ('hi', 'bye'), ('bye', 'hi'), ('bye', 'bye')]\n"
     ]
    }
   ],
   "source": [
    "#27  Nested List Comp â€“ Flatten word-character pairs\n",
    "\n",
    "tokens = [\"hi\", \"bye\"]\n",
    "pairs = [(w,ch) for w in tokens for ch in tokens]\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e09401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'project']\n"
     ]
    }
   ],
   "source": [
    "# 28 Clean and filter: lowercase + remove stopwords\n",
    "raw = [\"This\", \"is\", \"an\", \"NLP\", \"Project\"]\n",
    "stop = [\"this\", \"is\", \"an\"]\n",
    "\n",
    "clean = [w.lower() for w in raw if w.lower() not in stop]\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bbdec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world nlp \n"
     ]
    }
   ],
   "source": [
    "#29 Replace punctuation with space\n",
    "import string\n",
    "text = \"hello,world!nlp?\"\n",
    "clean = ''.join([\" \" if ch in string.punctuation else ch for ch in text])\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb650292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'even'), ('hello', 'odd'), ('yo', 'even'), ('transformer', 'odd')]\n"
     ]
    }
   ],
   "source": [
    "# 30  Tag tokens as even/odd length\n",
    "\n",
    "tokens = [\"hi\",\"hello\",\"yo\",\"transformer\"]\n",
    "tags = [(w,\"even\") if len(w)%2==0 else (w,\"odd\") for w in tokens]\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740aac81",
   "metadata": {},
   "source": [
    "##### mini tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a1052f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformers', 'changing', 'world']\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "sentence = \"Transformers are changing the world of AI and NLP\"\n",
    "# Hint: split + list comprehension + len() + lower()\n",
    "result = [w for w in sentence.lower().split() if len(w)>3]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065f9cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'ml', 'token']\n"
     ]
    }
   ],
   "source": [
    "#2 \n",
    "tokens = [\"data\", \"science123\", \"ml\", \"nlp4\", \"token\"]\n",
    "\n",
    "words  =[w for w in tokens if w.isalpha()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd19f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NLP', 3), ('is', 2), ('cool', 4), ('Transformers', 12), ('rock', 4), ('Deep', 4), ('learning', 8), ('wins', 4)]\n",
      "\n",
      "[3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#3 \n",
    "sentences = [\"NLP is cool\", \"Transformers rock\", \"Deep learning wins\"]\n",
    "# Output: [3, 2, 3]\n",
    "# Hint: Use split() inside list comp\n",
    "each_word_length = [(ch,len(ch)) for w in sentences for ch in w.split() ]\n",
    "print(each_word_length)\n",
    "print(\"\")\n",
    "sentence_length = [len(sentence.split()) for sentence in sentences]\n",
    "print(sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94de06c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for', 'if', 'while', 'func_name', '_hidden']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "import string as str \n",
    "tokens = [\"for\", \"if\", \"while\", \"2cool\", \"func_name\", \"!\", \"_hidden\"]\n",
    "identifiers = [w for w in tokens if w.isidentifier()]\n",
    "identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52ddbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'so', 'powerful', 'right', 'Sathvik?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 \n",
    "token_matrix = [[\"NLP\", \"is\"], [\"so\", \"powerful\"], [\"right\", \"Sathvik?\"]]\n",
    "# Output: ['NLP', 'is', 'so', 'powerful', 'right', 'Sathvik?']\n",
    "# Hint: nested list comprehension\n",
    "\n",
    "[word for row in token_matrix for word in row]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90a1c5",
   "metadata": {},
   "source": [
    "#### 4% harder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00e4acde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deeplearning', 'nlp', 'cool']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "tokens = [\"AI\", \"rocks!\", \"deepLearning\", \"123\", \"NLP\", \"ðŸ”¥\", \"python3\", \"is\", \"cool\"]\n",
    "\n",
    "# Output: ['deeplearning', 'nlp', 'cool']\n",
    "\n",
    "[word.lower() for word in tokens if (len(word)>=3 and word.isalpha())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c16f83f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'future', 'amazing']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Transformers are revolutionizing NLP\",\n",
    "    \"Large language models are the future\",\n",
    "    \"ChatGPT is amazing\"\n",
    "]\n",
    "\n",
    "# Output: ['NLP', 'future', 'amazing']\n",
    "\n",
    "[sentence.split()[-1] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae5d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp', 'is', 'text', 'processing', 'ai', 'for', 'good']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "paragraph_tokens = [\n",
    "    [\"NLP\", \"is\", \"fun!\"],\n",
    "    [\"Text\", \"123\", \"Processing\"],\n",
    "    [\"AI\", \"for\", \"Good\", \"ðŸ”¥\"]\n",
    "]\n",
    "\n",
    "# Output: ['nlp', 'is', 'text', 'processing', 'ai', 'for', 'good']\n",
    "\n",
    "[word.lower() for row in paragraph_tokens for word in row  if word.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc44aa8",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, sathvik!\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "def greet():\n",
    "    print(\"Hello, sathvik!\")\n",
    "\n",
    "greet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Sathvik, welcome to NLP!\n"
     ]
    }
   ],
   "source": [
    "#2ï¸âƒ£ Define a function that takes a name and prints a personalized greeting.\n",
    "def greet(name):\n",
    "    print(f'Hi {name}, welcome to NLP!')\n",
    "\n",
    "greet(\"Sathvik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "#3ï¸âƒ£ Return the square of a number.\n",
    "def squares(x):\n",
    "    return x**2\n",
    "print(squares(4))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6be2bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#4ï¸âƒ£ Return the length of a word.\n",
    "\n",
    "def word_length(word):\n",
    "    return len(word)\n",
    "print(word_length(\"sathvik\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c7c42ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sathvik is learning python\n"
     ]
    }
   ],
   "source": [
    "#âœ… Default Arguments\n",
    "# 5ï¸âƒ£ Function with a default argument for language.\n",
    "\n",
    "def intro (name,lang=\"python\"):\n",
    "    return f\"{name} is learning {lang}\"\n",
    "print(intro(\"sathvik\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad76475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER task can be done by spacy\n"
     ]
    }
   ],
   "source": [
    "# âœ… Keyword Arguments\n",
    "#6ï¸âƒ£ Keyword usage for flexible ordering.\n",
    "\n",
    "def describe_nlp(task,library):\n",
    "    return f\"{task} task can be done by {library}\"\n",
    "print(describe_nlp(library=\"spacy\",task=\"NER\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d45804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 16\n"
     ]
    }
   ],
   "source": [
    "# reurn Mutliple values\n",
    "#7ï¸âƒ£ Return both word count and character count.\n",
    "def analyze(text):\n",
    "    words = text.split(text)\n",
    "    return len(words),len(text)\n",
    "wc,cc = analyze(\"NLP is amazing !\")\n",
    "print(wc,cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9805c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 8ï¸âƒ£ Check if a word is long.\n",
    "def is_long(word):\n",
    "    return len(word)>5\n",
    "print(is_long(\"Deeplearning\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6655955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n",
      "IS\n",
      "FUN\n"
     ]
    }
   ],
   "source": [
    "#9ï¸âƒ£ Print all words in uppercase.\n",
    "def print_upper(words):\n",
    "    for word in words:\n",
    "        print(word.upper())\n",
    "print_upper([\"nlp\",\"is\",\"fun\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84fd051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”Ÿ Function calling another function.\n",
    "def clean(word):\n",
    "    return word.lower().strip()\n",
    "\n",
    "def clean_list(words):\n",
    "    return [clean(w) for w in words]\n",
    "\n",
    "print(clean_list([\"AI\",\" NLP  \"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e7ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatGPT is awesome\n"
     ]
    }
   ],
   "source": [
    "#11 1ï¸âƒ£1ï¸âƒ£ Accept variable number of inputs.\n",
    "\n",
    "def combine_words(*args):\n",
    "    return \" \".join(args)\n",
    "\n",
    "print(combine_words(\"chatGPT\",\"is\",\"awesome\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71785a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'BERT', 'task': 'QA'}\n"
     ]
    }
   ],
   "source": [
    "# 1ï¸âƒ£2ï¸âƒ£ Handle keyword arguments.\n",
    "\n",
    "def settings(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "print(settings(model = \"BERT\",task=\"QA\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#13 Lambda function \n",
    "def apply_twice(fn,x):\n",
    "    return fn(fn(x))\n",
    "print(apply_twice(lambda x:x+2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d9679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'cat', 'tre']\n"
     ]
    }
   ],
   "source": [
    "#14 lsit comprehensions in functions \n",
    "\n",
    "def lemmatize(word):\n",
    "    return word.lower().rstrip(\"s\")\n",
    "\n",
    "print([lemmatize(w) for w in [\"Dogs\",\"Cats\",\"Tress\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdba716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'is', 'the', 'future']\n"
     ]
    }
   ],
   "source": [
    "#1ï¸âƒ£5ï¸âƒ£ Clean and filter a sentence.\n",
    "def clean_sentence(sentence):\n",
    "    return [word.lower() for word in sentence.split() if word.isalpha()]\n",
    "\n",
    "print(clean_sentence(\"NLP is the future ðŸ’¡\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d481ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome product', 'loving it ', 'nlp is the future']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text).lower()\n",
    "\n",
    "reviews =  [\n",
    "    \"Awesome Product!!!\",\n",
    "    \"Loving it :)\",\n",
    "    \"NLP is the FUTURE...\"\n",
    "]\n",
    "\n",
    "cleaned_reviews = [clean_text(review) for review in reviews]\n",
    "print(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d959ac",
   "metadata": {},
   "source": [
    "### Tasks ~ 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d071c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'powerful']\n"
     ]
    }
   ],
   "source": [
    "# Input: \"NLP is Amazing and Powerful\"\n",
    "# Output: ['amazing', 'powerful']\n",
    "\n",
    "def normalize(sentence):\n",
    "    \n",
    "   return [word.lower() for word in sentence.split() if len(word)>3]\n",
    "    \n",
    "    \n",
    "print(normalize(\"NLP is Amazing and Powerful\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f94168c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 2âœ… Task 2: Check All Words Are Alphabetic\n",
    "# Input: ['nlp', 'is', 'fun']\n",
    "# Output: True\n",
    "\n",
    "# Input: ['nlp', '123']\n",
    "# Output: False\n",
    "\n",
    "def are_all_alpha(tokens):\n",
    "    return all(word.isalpha() for word in tokens)\n",
    "\n",
    "tokens = input(\"Enter words separated by space: \").split()\n",
    "print(are_all_alpha(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29106d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transformers': 12, 'NLP': 3, 'AI': 2}\n"
     ]
    }
   ],
   "source": [
    "# 3 âœ… Task 3: Count Word Lengths\n",
    "# Input: ['transformers', 'NLP', 'AI']\n",
    "# Output: {'transformers': 12, 'NLP': 3, 'AI': 2}\n",
    "\n",
    "def word_lengths(words):\n",
    "   return {word: len(word) for word in words}\n",
    "\n",
    "words = ['transformers', 'NLP', 'AI']\n",
    "print(word_lengths(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b161188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cool', 'AI']\n"
     ]
    }
   ],
   "source": [
    "#4 âœ… Task 4: Use Lambda to Extract Last Word\n",
    "# Input: [\"NLP is cool\", \"I love AI\"]\n",
    "# Output: ['cool', 'AI']\n",
    "\n",
    "def get_last_words(sentences):\n",
    "    return list(map(lambda w:w.split()[-1],sentences))\n",
    "\n",
    "sentences = [\"NLP is cool\", \"I love AI\"]\n",
    "print(get_last_words(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2154fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'cool']\n"
     ]
    }
   ],
   "source": [
    "# âœ… Task 5: Clean and Lowercase Tokens (using re)\n",
    "# Input: ['AI', 'rocks!', 'ML123', 'Cool']\n",
    "# Output: ['ai', 'cool']\n",
    "\n",
    "import re \n",
    "def clean_tokens(tokens):\n",
    "    return [word.lower() for word in tokens if re.fullmatch(r'[A-Za-z]+',word)]\n",
    "\n",
    "print(clean_tokens(['AI', 'rocks!', 'ML123', 'Cool']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e112916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
